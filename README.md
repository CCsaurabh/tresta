# [Tresta](https://github.com/CCsaurabh/tresta/)

Building beautiful RL products, related to supply chain, gaming, Economics and Finance Domain!

1. Cartpole Solved using Stable-baselines [Implemenation](https://github.com/HSaurabh0919/tresta/blob/main/Reinforcement_Learning/CartPole.ipynb).
2. Cartpole using A2C: Synchronous Advantage Actor Critic [Implementation](https://github.com/HSaurabh0919/tresta/blob/main/Reinforcement_Learning/CartPole_ActorCritic_Custom.ipynb).
3. DDQN implementation of Cart-Pole can be found [here](https://github.com/HSaurabh0919/tresta/blob/main/Reinforcement_Learning/DDQN_cartpole.ipynb) and also has comparison related to various epsilon-decay methods.

ðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜Š

### Plots
1. Comparison of effect of epsilon-decay approach on DDQN implementation for Cartpole environment.

- 1.1. Linear Epsilon Decay

![Linear Epsilon Decay](https://github.com/HSaurabh0919/tresta/blob/main/plots/linear_decay.png)

- 1.2. Exponential Epsilon Decay

![Exponential Epsilon Decay](https://github.com/HSaurabh0919/tresta/blob/main/plots/exponential_decay.png)

- 1.3. Exponential-Squared Epsilon Decay

![Exponential Squared Epsilon Decay](https://github.com/HSaurabh0919/tresta/blob/main/plots/exponential_squared_decay.png)

- 1.4. All epslion values

![ Decay](https://github.com/HSaurabh0919/tresta/blob/main/plots/epsilon_curves.png)

### REFERENCES: 
1. Cartpole custom A2C Implementation has been adapted from [here](https://github.com/higgsfield/RL-Adventure-2/blob/master/1.actor-critic.ipynb).
2. DDQN custom Implementation has been majorly inspired from [here](https://github.com/higgsfield/RL-Adventure/blob/master/2.double%20dqn.ipynb).
3. RL trading has been adapted from [here](https://github.com/nicknochnack/Reinforcement-Learning-for-Trading/blob/main/Reinforcement%20Learning%20GME%20Trading%20Tutorial.ipynb).
4. Trading environment has been used from [here](https://github.com/AminHP/gym-anytrading).
